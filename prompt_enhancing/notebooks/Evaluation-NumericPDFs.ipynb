{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from typing import cast\n",
    "import random\n",
    "\n",
    "from archaeo_super_prompt.dataset import MagohDataset\n",
    "from archaeo_super_prompt.modeling import legacy_predict\n",
    "from archaeo_super_prompt.modeling.struct_extract.main_transformer import MagohDataExtractor\n",
    "from archaeo_super_prompt.visualization import mlflow_logging as mmlflow\n",
    "from archaeo_super_prompt.config.env import getenv_or_throw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Pipeline try\n",
    "\n",
    "We have selected some PDF samples with already-encoded text to test a complete pipeline worflow until the structured data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## MLFLow experiment setup\n",
    "\n",
    "Be sure to have run the mlflow server with this command at in the `prompt_enhancing/` directory\n",
    "\n",
    "```sh\n",
    "just serve-tracer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"Numerical PDFs - Legacy Model\"\n",
    "mlflow.set_tracking_uri(f\"http://{getenv_or_throw(\"MLFLOW_HOST\")}:{getenv_or_throw(\"MLFLOW_PORT\")}\")\n",
    "mlflow.set_experiment(EXP_NAME)\n",
    "mlflow.dspy.autolog()\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Sample selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SAMPLES_FETCHED = 300\n",
    "SEED = 0.3\n",
    "\n",
    "ds = MagohDataset(MAX_SAMPLES_FETCHED, SEED, True)\n",
    "_selected_ids = [\n",
    "    # very good\n",
    "    33799, 34439, 38005, 36837, 36937, 37614, 37026, 37971, 36846, 36304, 34423, 36052,\n",
    "    37043, 36554, 989, 37007, 30897, 36351, 36308, 38013, 36011, 33828, 1221,\n",
    "    38039, 35429, 37065, 37116, 34452, 33441, 33062, 34939, 35918, 33689, 34508, 31035,\n",
    "    38220, 38092, 36979, 36854, 36207, 34915, 35688, 36359,\n",
    "    # not that good\n",
    "    31164, 32600, 33760, 32714, 31208, 30712,\n",
    "    ]\n",
    "selected_ids = set(_selected_ids)\n",
    "inputs = ds.get_files_for_batch(selected_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Pipeline run\n",
    "\n",
    "We use a dataframe-suitable version of the scikit-learn pipelines to pipe each module in this order :\n",
    "\n",
    "- ocr\n",
    "- layout text reading + chunking\n",
    "- strucured data extraction\n",
    "\n",
    "The LLM calls are traced by the MLFlow intergration and are viewable within links displayed by the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = legacy_predict.get_legacy_model()\n",
    "extraction_model = cast(MagohDataExtractor, pipeline.named_steps[\"extractor\"])\n",
    "input_example = ds.get_files_for_batch([\n",
    "    random.sample(sorted(selected_ids), 1)[0]\n",
    "])\n",
    "\n",
    "# text scan + chunking\n",
    "intermediate_inputs = pipeline.named_steps[\"vllm\"].transform(inputs)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # TODO: change the evaluation\n",
    "    # mmlflow.save_models(pipeline, input_example)\n",
    "    score_value = extraction_model.score(intermediate_inputs, ds)\n",
    "    score_results = extraction_model.score_results\n",
    "    mmlflow.save_metric_scores(score_value, score_results)\n",
    "    mmlflow.save_table_in_artifacts(score_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Evaluation result inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from archaeo_super_prompt.visualization import (\n",
    "        init_complete_vizualisation_engine, run_display_server\n",
    ")\n",
    "\n",
    "init_complete_vizualisation_engine(score_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_display_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "score_results.to_csv(str(Path(\"./results.csv\").resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.models.base_model import DocItem\n",
    "\n",
    "print(DocItem.label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry",
   "language": "python",
   "name": "poetry-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
